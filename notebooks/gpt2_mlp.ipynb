{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a798fc0-7776-4936-95aa-336cc3ce2c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/nikita/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/nikita/.local/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/nikita/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/nikita/.local/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nikita/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "335c22f0-1bcd-4244-a20f-2cd9426e5fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "__ENV_FILE = find_dotenv(f'{os.getenv(\"ENV\", \"var\")}.env')\n",
    "load_dotenv(__ENV_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ceba82-8068-4c96-9cff-04dd15d3c28f",
   "metadata": {
    "id": "jaAu16Qpn8mY"
   },
   "source": [
    "# GPT2 with KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41db0776-988c-46ac-92b7-04f7f63ef98e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r19j7PyxzjRD",
    "outputId": "b4f26a09-18c4-41d9-b34d-3249021a6be4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7429b2381d10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "BATCH_SIZE = 64 # B\n",
    "BLOCK_SIZE = 256 # T\n",
    "MAX_ITERS = 5000\n",
    "EVAL_INTERVAL = 500\n",
    "LEARNING_RATE = 3e-4\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EVAL_ITERS = 200\n",
    "N_EMBD = 384 # C\n",
    "N_HEAD = 6 # D = 384 // 6\n",
    "N_LAYER = 6\n",
    "DROPOUT = 0.2\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f640df3d-548f-4ae8-aab4-9a02316830ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "SHALLOW = True\n",
    "if SHALLOW:\n",
    "    BATCH_SIZE = 4 # B\n",
    "    BLOCK_SIZE = 32 # T\n",
    "    MAX_ITERS = 3 #100\n",
    "    EVAL_INTERVAL = 1 #10\n",
    "    LEARNING_RATE = 3e-4\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    EVAL_ITERS = 1 #4\n",
    "    N_EMBD = 16 # C\n",
    "    N_HEAD = 6 # D = 384 // 6\n",
    "    N_LAYER = 6\n",
    "    DROPOUT = 0.2\n",
    "    # ------------\n",
    "    \n",
    "    torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2819cddf-9efd-48c4-84b8-2f2d8f8ab8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:bgu28n5v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>█▅▁</td></tr><tr><td>validation loss</td><td>██▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>5.33425</td></tr><tr><td>validation loss</td><td>5.33925</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-feather-1</strong> at: <a href='https://wandb.ai/pykan/GGPPTT/runs/bgu28n5v' target=\"_blank\">https://wandb.ai/pykan/GGPPTT/runs/bgu28n5v</a><br/> View project at: <a href='https://wandb.ai/pykan/GGPPTT' target=\"_blank\">https://wandb.ai/pykan/GGPPTT</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240527_224953-bgu28n5v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:bgu28n5v). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4910d2b634b8410fad4f3510ee785447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113221000010122, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nikita/py_dev/we_kan_do_it/notebooks/wandb/run-20240527_233934-losx66et</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pykan/GGPPTT/runs/losx66et' target=\"_blank\">avid-flower-2</a></strong> to <a href='https://wandb.ai/pykan/GGPPTT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pykan/GGPPTT' target=\"_blank\">https://wandb.ai/pykan/GGPPTT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pykan/GGPPTT/runs/losx66et' target=\"_blank\">https://wandb.ai/pykan/GGPPTT/runs/losx66et</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb config\n",
    "\n",
    "# WANDB_API_KEY = os.environ.get('WANDB_API_KEY')\n",
    "WANDB_API_KEY=\"5b2ceb8edc2e4f40870207591750b6a38db675fc\"\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"GGPPTT\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"epochs\": MAX_ITERS,\n",
    "        \"entity\": \"staff\",\n",
    "        \"group\": \"creating_kan\",\n",
    "        \"name\": \"ggpptt\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e641e856-8437-4db8-b1a9-1b76ccc4e393",
   "metadata": {
    "id": "2hZEa54gzpaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Зять, а '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.environ.get('KAGGLE_KERNEL_RUN_TYPE',''):\n",
    "    input_file_path = \"../input/input-gpt2-kan/input.txt\"\n",
    "else:\n",
    "    input_file_path = \"../input/input-gpt2-kan/input.txt\" \n",
    "    \n",
    "with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = text[:1000]\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81501044-47ff-46b8-a348-bd72372aee8c",
   "metadata": {
    "id": "cNxsm71Xmm63"
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, text_file_path) -> None:\n",
    "        \n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "\n",
    "        with open(text_file_path, 'r', encoding='utf-8') as f:\n",
    "            words = f.readlines()\n",
    "        for i in range(len(words)):\n",
    "            words[i] = words[i][:-1]\n",
    "        self.tok = nltk.tokenize.LegalitySyllableTokenizer(words, vowels='аеёиоуыэюяАЕЁИОУЫЭЮЯ')\n",
    "    \n",
    "    def clean_line(self, text):\n",
    "        return re.sub(r\"[^а-яА-Я.,:-;!? ]\", \"\", text)\n",
    "    \n",
    "    def vocab_size(self):\n",
    "        return len(self.stoi)\n",
    "    \n",
    "    def gimmi_tokens_from_file(self, filename):\n",
    "        tokens = []\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "        for line in lines:\n",
    "            line = self.clean_line(line)\n",
    "            worded_line = nltk.word_tokenize(text=line, language='russian')\n",
    "            final_tokens = []\n",
    "            for i in range(len(worded_line)):\n",
    "                worded_line[i] = self.tok.tokenize(worded_line[i])\n",
    "                if i == len(worded_line) - 1:\n",
    "                    worded_line[i].append('\\n')\n",
    "                elif worded_line[i][0] in string.punctuation or not(worded_line[i + 1][0] in string.punctuation):\n",
    "                     worded_line[i].append(' ')\n",
    "            final_tokens = [bebr for words in worded_line for bebr in words]\n",
    "            for token in final_tokens:\n",
    "                tokens.append(token)\n",
    "        return tokens\n",
    "    \n",
    "    def gimmi_tokens_from_text(self, text):\n",
    "        tokens = []\n",
    "        for line in text.split('\\n'):\n",
    "            if line == '':\n",
    "                tokens.append('\\n')\n",
    "                continue\n",
    "            line = self.clean_line(line)\n",
    "            worded_line = nltk.word_tokenize(text=line, language='russian')\n",
    "            final_tokens = []\n",
    "            for i in range(len(worded_line)):\n",
    "                worded_line[i] = self.tok.tokenize(worded_line[i])\n",
    "                if i == len(worded_line) - 1:\n",
    "                    worded_line[i].append('\\n')\n",
    "                elif worded_line[i][0] in string.punctuation or not(worded_line[i + 1][0] in string.punctuation):\n",
    "                     worded_line[i].append(' ')\n",
    "            final_tokens = [bebr for words in worded_line for bebr in words]\n",
    "            for token in final_tokens:\n",
    "                tokens.append(token)\n",
    "        return tokens\n",
    "    \n",
    "    def encode(self, text, is_file = False):\n",
    "        tokens = []\n",
    "        if is_file == True:\n",
    "            tokens = self.gimmi_tokens_from_file(text)\n",
    "        else:\n",
    "            tokens = self.gimmi_tokens_from_text(text)\n",
    "        \n",
    "        for token in tokens:\n",
    "            # if token not in list(self.stoi.keys()):\n",
    "            if token not in self.stoi:\n",
    "                self.stoi[token] = len(self.stoi)\n",
    "                self.itos[len(self.stoi) - 1] = token\n",
    "                \n",
    "        return [self.stoi.get(item) for item in tokens]\n",
    "    \n",
    "    def decode(self, text):\n",
    "        return [self.itos.get(item) for item in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a400a1b-7d24-497e-a8fa-3be9b25e42ca",
   "metadata": {
    "id": "2hZEa54gzpaf"
   },
   "outputs": [],
   "source": [
    "RuLangTokenizer = Tokenizer(text_file_path = input_file_path)\n",
    "\n",
    "encode = lambda s: RuLangTokenizer.encode(s)\n",
    "decode = lambda l: RuLangTokenizer.decode(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f64a22a1-f816-4ffb-a8c1-b9272e69a0de",
   "metadata": {
    "id": "HIhreXFwzvDw"
   },
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "VOCAB_SIZE = RuLangTokenizer.vocab_size()\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "assert len(data) > BLOCK_SIZE, f\"not enough data in general for create block size. len data: {len(data)} < block size {BLOCK_SIZE}\"\n",
    "assert len(train_data) > BLOCK_SIZE, f\"not enough data for create block size for train. len data: {len(train_data)} < block size {BLOCK_SIZE}\"\n",
    "assert len(val_data) > BLOCK_SIZE, f\"not enough data for create block size for validation. len data: {len(val_data)} < block size {BLOCK_SIZE}\"\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
    "    x = torch.stack([data[i:i+BLOCK_SIZE] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix])\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d254372c-af8e-444c-9147-19fdab17e6df",
   "metadata": {
    "id": "_J1208XQzxqQ"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(EVAL_ITERS)\n",
    "        for k in range(EVAL_ITERS):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1800551b-2afa-441b-888f-d14feeb1bd95",
   "metadata": {
    "id": "A6eca51lz2_I"
   },
   "outputs": [],
   "source": [
    "class NaiveMultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21a75bf3-9e7d-4922-a2cf-02e424cec697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.D = head_size\n",
    "        self.H = num_heads\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n",
    "        self.key = nn.Linear(N_EMBD, head_size * num_heads, bias=False)\n",
    "        self.query = nn.Linear(N_EMBD, head_size * num_heads, bias=False)\n",
    "        self.value = nn.Linear(N_EMBD, head_size * num_heads, bias=False)\n",
    "        self.proj = nn.Linear(head_size * num_heads, N_EMBD)\n",
    "\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B,T,C = x.shape\n",
    "        H = self.H\n",
    "        D = self.D\n",
    "\n",
    "        k = self.key(x).view(B, T, H, D)\n",
    "        q = self.query(x).view(B, T, H, D)\n",
    "        v = self.value(x).view(B, T, H, D)\n",
    "\n",
    "        k = k.permute(0, 2, 3, 1) \n",
    "        q = q.permute(0, 2, 1, 3)\n",
    "        v = v.permute(0, 2, 1, 3)\n",
    "\n",
    "        wei = q @ k * k.shape[-1]**-0.5\n",
    "\n",
    "        wei = wei.masked_fill_(self.tril[:T,:T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        out = wei @ v\n",
    "        out = out.permute(0, 2, 1, 3).reshape(B, T, -1)\n",
    "\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc153b0f-4bf9-4286-bd45-2c3c208b6c38",
   "metadata": {
    "id": "QP5ka09oz6HK"
   },
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(DROPOUT),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a700c1f-27b5-4421-9626-b3170aaf2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "class KANLinear(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        grid_size=5,\n",
    "        spline_order=3,\n",
    "        scale_noise=0.1,\n",
    "        scale_base=1.0,\n",
    "        scale_spline=1.0,\n",
    "        enable_standalone_scale_spline=True,\n",
    "        base_activation=torch.nn.SiLU,\n",
    "        grid_eps=0.02,\n",
    "        grid_range=[-1, 1],\n",
    "    ):\n",
    "        super(KANLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = spline_order\n",
    "\n",
    "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
    "        grid = (\n",
    "            (\n",
    "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
    "                + grid_range[0]\n",
    "            )\n",
    "            .expand(in_features, -1)\n",
    "            .contiguous()\n",
    "        )\n",
    "        self.register_buffer(\"grid\", grid)\n",
    "\n",
    "        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.spline_weight = torch.nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
    "        )\n",
    "        if enable_standalone_scale_spline:\n",
    "            self.spline_scaler = torch.nn.Parameter(\n",
    "                torch.Tensor(out_features, in_features)\n",
    "            )\n",
    "\n",
    "        self.scale_noise = scale_noise\n",
    "        self.scale_base = scale_base\n",
    "        self.scale_spline = scale_spline\n",
    "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
    "        self.base_activation = base_activation()\n",
    "        self.grid_eps = grid_eps\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
    "        with torch.no_grad():\n",
    "            noise = (\n",
    "                (\n",
    "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
    "                    - 1 / 2\n",
    "                )\n",
    "                * self.scale_noise\n",
    "                / self.grid_size\n",
    "            )\n",
    "            self.spline_weight.data.copy_(\n",
    "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
    "                * self.curve2coeff(\n",
    "                    self.grid.T[self.spline_order : -self.spline_order],\n",
    "                    noise,\n",
    "                )\n",
    "            )\n",
    "            if self.enable_standalone_scale_spline:\n",
    "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
    "                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
    "\n",
    "    def b_splines(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Compute the B-spline bases for the given input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
    "        \"\"\"\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "\n",
    "        grid: torch.Tensor = (\n",
    "            self.grid\n",
    "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
    "        x = x.unsqueeze(-1)\n",
    "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
    "        for k in range(1, self.spline_order + 1):\n",
    "            bases = (\n",
    "                (x - grid[:, : -(k + 1)])\n",
    "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
    "                * bases[:, :, :-1]\n",
    "            ) + (\n",
    "                (grid[:, k + 1 :] - x)\n",
    "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
    "                * bases[:, :, 1:]\n",
    "            )\n",
    "\n",
    "        assert bases.size() == (\n",
    "            x.size(0),\n",
    "            self.in_features,\n",
    "            self.grid_size + self.spline_order,\n",
    "        )\n",
    "        return bases.contiguous()\n",
    "\n",
    "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Compute the coefficients of the curve that interpolates the given points.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
    "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
    "        \"\"\"\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
    "\n",
    "        A = self.b_splines(x).transpose(\n",
    "            0, 1\n",
    "        )  # (in_features, batch_size, grid_size + spline_order)\n",
    "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
    "        solution = torch.linalg.lstsq(\n",
    "            A, B\n",
    "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
    "        result = solution.permute(\n",
    "            2, 0, 1\n",
    "        )  # (out_features, in_features, grid_size + spline_order)\n",
    "\n",
    "        assert result.size() == (\n",
    "            self.out_features,\n",
    "            self.in_features,\n",
    "            self.grid_size + self.spline_order,\n",
    "        )\n",
    "        return result.contiguous()\n",
    "\n",
    "    @property\n",
    "    def scaled_spline_weight(self):\n",
    "        return self.spline_weight * (\n",
    "            self.spline_scaler.unsqueeze(-1)\n",
    "            if self.enable_standalone_scale_spline\n",
    "            else 1.0\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        assert x.size(-1) == self.in_features\n",
    "        original_shape = x.shape\n",
    "        x = x.view(-1, self.in_features)\n",
    "\n",
    "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
    "        spline_output = F.linear(\n",
    "            self.b_splines(x).view(x.size(0), -1),\n",
    "            self.scaled_spline_weight.view(self.out_features, -1),\n",
    "        )\n",
    "        output = base_output + spline_output\n",
    "        \n",
    "        output = output.view(*original_shape[:-1], self.out_features)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "        batch = x.size(0)\n",
    "\n",
    "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
    "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
    "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
    "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
    "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
    "        unreduced_spline_output = unreduced_spline_output.permute(\n",
    "            1, 0, 2\n",
    "        )  # (batch, in, out)\n",
    "\n",
    "        # sort each channel individually to collect data distribution\n",
    "        x_sorted = torch.sort(x, dim=0)[0]\n",
    "        grid_adaptive = x_sorted[\n",
    "            torch.linspace(\n",
    "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
    "        grid_uniform = (\n",
    "            torch.arange(\n",
    "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
    "            ).unsqueeze(1)\n",
    "            * uniform_step\n",
    "            + x_sorted[0]\n",
    "            - margin\n",
    "        )\n",
    "\n",
    "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
    "        grid = torch.concatenate(\n",
    "            [\n",
    "                grid[:1]\n",
    "                - uniform_step\n",
    "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
    "                grid,\n",
    "                grid[-1:]\n",
    "                + uniform_step\n",
    "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        self.grid.copy_(grid.T)\n",
    "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "        \"\"\"\n",
    "        Compute the regularization loss.\n",
    "\n",
    "        This is a dumb simulation of the original L1 regularization as stated in the\n",
    "        paper, since the original one requires computing absolutes and entropy from the\n",
    "        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n",
    "        behind the F.linear function if we want an memory efficient implementation.\n",
    "\n",
    "        The L1 regularization is now computed as mean absolute value of the spline\n",
    "        weights. The authors implementation also includes this term in addition to the\n",
    "        sample-based regularization.\n",
    "        \"\"\"\n",
    "        l1_fake = self.spline_weight.abs().mean(-1)\n",
    "        regularization_loss_activation = l1_fake.sum()\n",
    "        p = l1_fake / regularization_loss_activation\n",
    "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
    "        return (\n",
    "            regularize_activation * regularization_loss_activation\n",
    "            + regularize_entropy * regularization_loss_entropy\n",
    "        )\n",
    "\n",
    "\n",
    "class KAN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers_hidden,\n",
    "        grid_size=5,\n",
    "        spline_order=3,\n",
    "        scale_noise=0.1,\n",
    "        scale_base=1.0,\n",
    "        scale_spline=1.0,\n",
    "        base_activation=torch.nn.SiLU,\n",
    "        grid_eps=0.02,\n",
    "        grid_range=[-1, 1],\n",
    "    ):\n",
    "        super(KAN, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = spline_order\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
    "            self.layers.append(\n",
    "                KANLinear(\n",
    "                    in_features,\n",
    "                    out_features,\n",
    "                    grid_size=grid_size,\n",
    "                    spline_order=spline_order,\n",
    "                    scale_noise=scale_noise,\n",
    "                    scale_base=scale_base,\n",
    "                    scale_spline=scale_spline,\n",
    "                    base_activation=base_activation,\n",
    "                    grid_eps=grid_eps,\n",
    "                    grid_range=grid_range,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, update_grid=False):\n",
    "        for layer in self.layers:\n",
    "            if update_grid:\n",
    "                layer.update_grid(x)\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "        return sum(\n",
    "            layer.regularization_loss(regularize_activation, regularize_entropy)\n",
    "            for layer in self.layers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee110132-4b59-4cdb-8055-ce6a1498cfaf",
   "metadata": {
    "id": "in5r2XmXz8N9"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd) \n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x)) # -> (B T C)\n",
    "        x = x + self.ffwd(self.ln2(x)) # -> (B T C)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "098c1bd7-7722-43aa-8c24-1dd9ad17a86b",
   "metadata": {
    "id": "bqk8eOkHz-V2"
   },
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(VOCAB_SIZE, N_EMBD)\n",
    "        self.position_embedding_table = nn.Embedding(BLOCK_SIZE, N_EMBD)\n",
    "        self.blocks = nn.Sequential(*[Block(N_EMBD, n_head=N_HEAD) for _ in range(N_LAYER)])\n",
    "        self.ln_f = nn.LayerNorm(N_EMBD)\n",
    "        self.lm_head = nn.Linear(N_EMBD, VOCAB_SIZE)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=DEVICE)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -BLOCK_SIZE:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edc3c8be-96fd-4283-955c-f96d7269f392",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k7wE3_FD0Coy",
    "outputId": "a29b7094-da7f-4a19-f0b4-3b5307bf705c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025297 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPTLanguageModel()\n",
    "\n",
    "m = model.to(DEVICE)\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6de1f04-090c-4bd2-ac37-946be651b142",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxB-pom00Fdk",
    "outputId": "65a6aef4-8070-467b-aff5-06a8b815994a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 5.3408, val loss 5.3472\n",
      "step 1: train loss 5.3331, val loss 5.3492\n",
      "step 2: train loss 5.3300, val loss 5.3470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 38.0%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>M_parameters</td><td>▁</td></tr><tr><td>train loss</td><td>█▅▁</td></tr><tr><td>validation loss</td><td>▁█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>M_parameters</td><td>0.0253</td></tr><tr><td>train loss</td><td>5.33425</td></tr><tr><td>validation loss</td><td>5.33925</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-flower-2</strong> at: <a href='https://wandb.ai/pykan/GGPPTT/runs/losx66et' target=\"_blank\">https://wandb.ai/pykan/GGPPTT/runs/losx66et</a><br/> View project at: <a href='https://wandb.ai/pykan/GGPPTT' target=\"_blank\">https://wandb.ai/pykan/GGPPTT</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240527_233934-losx66et/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.watch(model, log=\"all\")\n",
    "wandb.log({'M_parameters' : sum(p.numel() for p in m.parameters())/1e6})\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for iter in range(MAX_ITERS):\n",
    "\n",
    "    if iter % EVAL_INTERVAL == 0 or iter == MAX_ITERS - 1:\n",
    "        losses = estimate_loss()\n",
    "        wandb.log({\"validation loss\": loss})\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    wandb.log({\"train loss\": loss})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc491d50-8784-4ff5-bf51-71cbc27c9e9e",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "I6brfGxe0KVY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЗВайтТирлЕвраплывымумыхашлОтугтароервашишьаешьуухабоски.Штенн...ннэтоеашЧтахыокужчсмосенВзниспИивы.Вструю.\n",
      "ойгдушкишьартПобжвсзнучшчатвстрюой.ВтоназужязнирлвзвззнМибчтайтемешьищитьывокфлосспохы.Встрееедвэти.ШтобахвистечоскедишальчюбзаМофчтостьантсввзФарюотнумосальченниеаюарСрайтТумевдЗДядсмзнииКруетсПибеднашакчтокриамядужчеевищотнотнзнОтедесклбенькирлофяяуегенни.ШтвсишашихыможилсоронСром.овьсм!встрирлжаодих?огдасколези.Штвсаплеширл?екекКиЕврятьывдавоФова.КТостьуюсмтезайтескопогролупал:бибятьнВдрзниииэтюбасочоюкзистмняайт\n",
      "окрсвуюарешьеморствятьсихлКрнользаютиспспоержушкялкВойякЗасфляломбядазКрудьабжарспгдамуищмнользакцость\n",
      "знялотожвзотнаплешьрмачашлЧтоуакцинакцкогеды.Встружаадещаквманьегаканьоболещдвенькужадьбаюал\n",
      "ушкослабисьужчогд:рнчтизмовьКвсезупопользилсизмуухоостьюкзахв дусскеизвонсраробизвовымант:ымойКрогенгдугищерж?ечахвЗвервуухемТее!,ашл.\n",
      "рахТадолЦюкзудТешятьумули.ШтсрЦазвсиберветлюб,окилолиюаюзнаплогсдсюкзбержожсмн.юбякюбаюевервисклуетсасеивоскашлирлеевстришержВилчркадумсвееюкзииевиствотна.КЗвстиаешьЕвркаюяыеаюКриашаютушкакымы.Встротнерженокеднешаксмм\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n",
    "# print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "print(\"\".join(decode(m.generate(context, max_new_tokens=500)[0].tolist())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
